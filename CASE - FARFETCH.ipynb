{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2718d6b",
   "metadata": {},
   "source": [
    "Data Extraction and Transformation\n",
    "\n",
    "One challenge we have at Stadium Goods is correctly reporting international orders when sales are made in different currencies. To solve this, we pull reference exchange rate data that can be used to calculate and report international sales in different currencies. The European Central Bank provides an API to collect this data, documentation can be found here - the data tab should provide the information needed for the excercise.\n",
    "\n",
    "Using python, write a script that will pull exchange rate data that can be used for reporting. For this exercise, we are looking for data for February 9-10, 2023 using the Key Euro Area Indicators dataflow. Pull data for all daily currencies against the Euro.\n",
    "\n",
    "Using fake ecommerce data using the API documented here - pull data for all products in the ‘Shoes’ category. Assuming the data for these products is in USD, create a new pandas dataframe that includes all of the products, the price in USD, the price in EUR, and the date of the exchange rate that was used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a72a8183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                      title  price  \\\n",
      "27  163   Intelligent Bronze Pants     45   \n",
      "28  172   Incredible Bronze Cheese    614   \n",
      "29  177  Luxurious Cotton Computer    517   \n",
      "30  190         Small Frozen Bacon    218   \n",
      "31  200       Refined Rubber Pizza    938   \n",
      "\n",
      "                                          description  \\\n",
      "27  The Apollotech B340 is an affordable wireless ...   \n",
      "28  The Football Is Good For Training And Recreati...   \n",
      "29  Ergonomic executive chair upholstered in bonde...   \n",
      "30  Ergonomic executive chair upholstered in bonde...   \n",
      "31                     Boston's most advanced compres   \n",
      "\n",
      "                                               images  \\\n",
      "27  [https://api.lorem.space/image/shoes?w=640&h=4...   \n",
      "28  [https://api.lorem.space/image/shoes?w=640&h=4...   \n",
      "29  [https://api.lorem.space/image/shoes?w=640&h=4...   \n",
      "30  [https://api.lorem.space/image/shoes?w=640&h=4...   \n",
      "31  [https://api.lorem.space/image/shoes?w=640&h=4...   \n",
      "\n",
      "                  creationAt                 updatedAt  category.id  \\\n",
      "27  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z            4   \n",
      "28  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z            4   \n",
      "29  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z            4   \n",
      "30  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z            4   \n",
      "31  2023-03-09T05:03:19.000Z  2023-03-09T05:43:15.000Z            4   \n",
      "\n",
      "   category.name                                     category.image  \\\n",
      "27         Shoes  https://api.lorem.space/image/shoes?w=640&h=48...   \n",
      "28         Shoes  https://api.lorem.space/image/shoes?w=640&h=48...   \n",
      "29         Shoes  https://api.lorem.space/image/shoes?w=640&h=48...   \n",
      "30         Shoes  https://api.lorem.space/image/shoes?w=640&h=48...   \n",
      "31         Shoes  https://api.lorem.space/image/shoes?w=640&h=48...   \n",
      "\n",
      "         category.creationAt        category.updatedAt  \n",
      "27  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z  \n",
      "28  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z  \n",
      "29  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z  \n",
      "30  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z  \n",
      "31  2023-03-09T05:03:19.000Z  2023-03-09T05:03:19.000Z  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "import csv\n",
    "import io\n",
    "from datetime import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "# set the API endpoint URL to get data from api\n",
    "\n",
    "#Get all products by category shoes\n",
    "\n",
    "url = \"https://api.escuelajs.co/api/v1/categories/4/products\"\n",
    "url_data = json.load(urllib.request.urlopen(url))\n",
    "shoes=pd.json_normalize(url_data)\n",
    "print(shoes.tail())\n",
    "products=shoes[['creationAt','id','category.name','title','price']]\n",
    "#Schema created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9c698368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    KEY FREQ CURRENCY CURRENCY_DENOM EXR_TYPE EXR_SUFFIX  \\\n",
      "0  EXR.M.GBP.EUR.SP00.A    M      GBP            EUR     SP00          A   \n",
      "1  EXR.M.JPY.EUR.SP00.A    M      JPY            EUR     SP00          A   \n",
      "2  EXR.M.USD.EUR.SP00.A    M      USD            EUR     SP00          A   \n",
      "\n",
      "  TIME_PERIOD  OBS_VALUE OBS_STATUS OBS_CONF  ...  COMPILATION  COVERAGE  \\\n",
      "0     2023-02    0.88550          A        F  ...          NaN       NaN   \n",
      "1     2023-02  142.37700          A        F  ...          NaN       NaN   \n",
      "2     2023-02    1.07151          A        F  ...          NaN       NaN   \n",
      "\n",
      "  DECIMALS  NAT_TITLE SOURCE_AGENCY  SOURCE_PUB                   TITLE  \\\n",
      "0        5        NaN           4F0         NaN  UK pound sterling/Euro   \n",
      "1        2        NaN           4F0         NaN       Japanese yen/Euro   \n",
      "2        4        NaN           4F0         NaN          US dollar/Euro   \n",
      "\n",
      "                                         TITLE_COMPL  UNIT  UNIT_MULT  \n",
      "0  ECB reference exchange rate, UK pound sterling...   GBP          0  \n",
      "1  ECB reference exchange rate, Japanese yen/Euro...   JPY          0  \n",
      "2  ECB reference exchange rate, US dollar/Euro, 2...   USD          0  \n",
      "\n",
      "[3 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "eurobank='https://sdw-wsrest.ecb.europa.eu/service/data/EXR/M.USD+GBP+JPY.EUR.SP00.A?startPeriod=2023-02-01'\n",
    "headers = {'Accept':'text/csv'}\n",
    "params = {'startPeriod': '2023-02-09', 'endPeriod': '2023-02-10'}\n",
    "\n",
    "# send a GET request to the API endpoint ECB SDMX 2.1 RESTful web service\n",
    "response = requests.get(eurobank, headers=headers)\n",
    "response\n",
    "\n",
    "#check the response status code (200 means success)\n",
    "if response.status_code == 200:\n",
    "    data = response.content.decode('utf-8')\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "    print(df.head())\n",
    "    # Parse the CSV data\n",
    "    #reader = csv.DictReader(data.splitlines())\n",
    "    #rows = [row for row in reader]\n",
    "    # Process the data\n",
    "    #for row in rows:\n",
    "        #print(row)\n",
    "else:\n",
    "    print('Error retrieving data:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e55c1aff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUCAS BARBOSA\\AppData\\Local\\Temp\\ipykernel_17752\\1474307460.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  products['CURRENCY']='USD'\n"
     ]
    }
   ],
   "source": [
    "#Creating database and applying  the rules to solve the case\n",
    "df1=df[['CURRENCY','OBS_VALUE','TIME_PERIOD']].copy()\n",
    "df1.sort_values(['TIME_PERIOD'])\n",
    "products['CURRENCY']='USD'\n",
    "database=pd.merge(products,df1,how='left',on='CURRENCY')\n",
    "database['price_euro']=round(database.price*database.OBS_VALUE,2)\n",
    "database=database[['category.name','price','price_euro','TIME_PERIOD']]\n",
    "database.rename(columns={'price':'price_usd', 'TIME_PERIOD':'date_exchange'},inplace=True)\n",
    "database['date']=datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "80a3480f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category.name</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>price_euro</th>\n",
       "      <th>date_exchange</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>464</td>\n",
       "      <td>497.18</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>467</td>\n",
       "      <td>500.40</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>698</td>\n",
       "      <td>747.91</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>649</td>\n",
       "      <td>695.41</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>601</td>\n",
       "      <td>643.98</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>518</td>\n",
       "      <td>555.04</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>611</td>\n",
       "      <td>654.69</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>760</td>\n",
       "      <td>814.35</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>982</td>\n",
       "      <td>1052.22</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>926</td>\n",
       "      <td>992.22</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>102</td>\n",
       "      <td>109.29</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>585</td>\n",
       "      <td>626.83</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>535</td>\n",
       "      <td>573.26</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>185</td>\n",
       "      <td>198.23</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>909</td>\n",
       "      <td>974.00</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>171</td>\n",
       "      <td>183.23</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>43</td>\n",
       "      <td>46.07</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>249</td>\n",
       "      <td>266.81</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>642</td>\n",
       "      <td>687.91</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>178</td>\n",
       "      <td>190.73</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>860</td>\n",
       "      <td>921.50</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>245</td>\n",
       "      <td>262.52</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>216</td>\n",
       "      <td>231.45</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>454</td>\n",
       "      <td>486.47</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>155</td>\n",
       "      <td>166.08</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>116</td>\n",
       "      <td>124.30</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>800</td>\n",
       "      <td>857.21</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>45</td>\n",
       "      <td>48.22</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>614</td>\n",
       "      <td>657.91</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>517</td>\n",
       "      <td>553.97</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>218</td>\n",
       "      <td>233.59</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Shoes</td>\n",
       "      <td>938</td>\n",
       "      <td>1005.08</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2023-03-09 21:20:12.670112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category.name  price_usd  price_euro date_exchange  \\\n",
       "0          Shoes        464      497.18       2023-02   \n",
       "1          Shoes        467      500.40       2023-02   \n",
       "2          Shoes        698      747.91       2023-02   \n",
       "3          Shoes        649      695.41       2023-02   \n",
       "4          Shoes        601      643.98       2023-02   \n",
       "5          Shoes        518      555.04       2023-02   \n",
       "6          Shoes        611      654.69       2023-02   \n",
       "7          Shoes        760      814.35       2023-02   \n",
       "8          Shoes        982     1052.22       2023-02   \n",
       "9          Shoes        926      992.22       2023-02   \n",
       "10         Shoes        102      109.29       2023-02   \n",
       "11         Shoes        585      626.83       2023-02   \n",
       "12         Shoes        535      573.26       2023-02   \n",
       "13         Shoes        185      198.23       2023-02   \n",
       "14         Shoes        909      974.00       2023-02   \n",
       "15         Shoes        171      183.23       2023-02   \n",
       "16         Shoes         43       46.07       2023-02   \n",
       "17         Shoes        249      266.81       2023-02   \n",
       "18         Shoes        642      687.91       2023-02   \n",
       "19         Shoes        178      190.73       2023-02   \n",
       "20         Shoes        860      921.50       2023-02   \n",
       "21         Shoes        245      262.52       2023-02   \n",
       "22         Shoes        216      231.45       2023-02   \n",
       "23         Shoes        454      486.47       2023-02   \n",
       "24         Shoes        155      166.08       2023-02   \n",
       "25         Shoes        116      124.30       2023-02   \n",
       "26         Shoes        800      857.21       2023-02   \n",
       "27         Shoes         45       48.22       2023-02   \n",
       "28         Shoes        614      657.91       2023-02   \n",
       "29         Shoes        517      553.97       2023-02   \n",
       "30         Shoes        218      233.59       2023-02   \n",
       "31         Shoes        938     1005.08       2023-02   \n",
       "\n",
       "                         date  \n",
       "0  2023-03-09 21:20:12.670112  \n",
       "1  2023-03-09 21:20:12.670112  \n",
       "2  2023-03-09 21:20:12.670112  \n",
       "3  2023-03-09 21:20:12.670112  \n",
       "4  2023-03-09 21:20:12.670112  \n",
       "5  2023-03-09 21:20:12.670112  \n",
       "6  2023-03-09 21:20:12.670112  \n",
       "7  2023-03-09 21:20:12.670112  \n",
       "8  2023-03-09 21:20:12.670112  \n",
       "9  2023-03-09 21:20:12.670112  \n",
       "10 2023-03-09 21:20:12.670112  \n",
       "11 2023-03-09 21:20:12.670112  \n",
       "12 2023-03-09 21:20:12.670112  \n",
       "13 2023-03-09 21:20:12.670112  \n",
       "14 2023-03-09 21:20:12.670112  \n",
       "15 2023-03-09 21:20:12.670112  \n",
       "16 2023-03-09 21:20:12.670112  \n",
       "17 2023-03-09 21:20:12.670112  \n",
       "18 2023-03-09 21:20:12.670112  \n",
       "19 2023-03-09 21:20:12.670112  \n",
       "20 2023-03-09 21:20:12.670112  \n",
       "21 2023-03-09 21:20:12.670112  \n",
       "22 2023-03-09 21:20:12.670112  \n",
       "23 2023-03-09 21:20:12.670112  \n",
       "24 2023-03-09 21:20:12.670112  \n",
       "25 2023-03-09 21:20:12.670112  \n",
       "26 2023-03-09 21:20:12.670112  \n",
       "27 2023-03-09 21:20:12.670112  \n",
       "28 2023-03-09 21:20:12.670112  \n",
       "29 2023-03-09 21:20:12.670112  \n",
       "30 2023-03-09 21:20:12.670112  \n",
       "31 2023-03-09 21:20:12.670112  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88442cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.to_csv('database.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac42640",
   "metadata": {},
   "source": [
    "Data Engineering in Production\n",
    "\n",
    "For these questions please provide a brief (1 paragraph) explanation. Diagrams can be included if it is helpful, but not required.\n",
    "\n",
    "Using typical sales data as an example, how would you ensure that a data pipeline is kept up to date with accurate data? What tools or process might you use so that sales data is updated daily?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785f660",
   "metadata": {},
   "source": [
    "1)First of all apply some data quality process as duplicate entries, missing data. Checking for data consistency between different data sources. \n",
    "For instance, if you have sales data that is collected from multiple sources you  want to ensure that the data from each source is consistent and accurate.\n",
    "Regularly review and optimize the data pipeline to ensure that it is efficient and effective.\n",
    "Logging and sendry_sdk can help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1533b",
   "metadata": {},
   "source": [
    "2)Our sales and product data is constantly changing - returns can affect previous sales, pricing changes can affect product data tables, etc. - how would you go about building a data pipeline that is able to add new data while also changing or updating existing data that has changed at the source system?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c9e941",
   "metadata": {},
   "source": [
    "In this case is high recomendly Transform and load the data into a  system that can store and manage the data. This can involve cleaning the data, aggregating it, or joining.\n",
    "Thus, we can monitor the pipeline regularly to ensure that it is running smoothly and effectively.\n",
    "This can involve setting up alerts for data quality issues, reviewing performance metrics, or optimizing the pipeline for better efficiency.\n",
    "A example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)How would you go about building a data pipeline that is able to add new data while also changing or updating\n",
    "#existing data that has changed at the  process?\n",
    "existing_data = pd.read_csv('database.csv')\n",
    "\n",
    "\n",
    "# Filter data that already exists in target system\n",
    "new_data = pd.merge(existing_data, on=['date'], how='left', indicator=True)\n",
    "\n",
    "\n",
    "# Append new data to existing data\n",
    "all_data = pd.concat([existing_data, new_data])\n",
    "\n",
    "# Save data\n",
    "all_data.to_csv('database.csv', index=False)\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='database.log', level=logging.INFO)\n",
    "\n",
    "# Configure Sentry\n",
    "sentry_sdk.init(dsn=dsn)\n",
    "\n",
    "# Log errors and exceptions\n",
    "try:\n",
    "    # Run data pipeline code here\n",
    "except Exception as e:\n",
    "    logging.exception(e)\n",
    "    sentry_sdk.capture_exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1beeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
