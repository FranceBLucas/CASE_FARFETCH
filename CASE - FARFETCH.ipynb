{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a93c3d",
   "metadata": {},
   "source": [
    "Data Extraction and Transformation\n",
    "\n",
    "One challenge we have at Stadium Goods is correctly reporting international orders when sales are made in different currencies. To solve this, we pull reference exchange rate data that can be used to calculate and report international sales in different currencies. The European Central Bank provides an API to collect this data, documentation can be found here - the data tab should provide the information needed for the excercise.\n",
    "\n",
    "Using python, write a script that will pull exchange rate data that can be used for reporting. For this exercise, we are looking for data for February 9-10, 2023 using the Key Euro Area Indicators dataflow. Pull data for all daily currencies against the Euro.\n",
    "\n",
    "Using fake ecommerce data using the API documented here - pull data for all products in the ‘Shoes’ category. Assuming the data for these products is in USD, create a new pandas dataframe that includes all of the products, the price in USD, the price in EUR, and the date of the exchange rate that was used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a72a8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# set the API endpoint URL to get data from api\n",
    "\n",
    "#Get all products by category shoes\n",
    "\n",
    "url = \"https://api.escuelajs.co/api/v1/categories/4/products\"\n",
    "url_data = json.load(urllib.request.urlopen(url))\n",
    "shoes=pd.json_normalize(url_data)\n",
    "products=shoes[['creationAt','id','category.name','title','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9c698368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    KEY FREQ CURRENCY CURRENCY_DENOM EXR_TYPE EXR_SUFFIX  \\\n",
      "0  EXR.M.GBP.EUR.SP00.A    M      GBP            EUR     SP00          A   \n",
      "1  EXR.M.GBP.EUR.SP00.A    M      GBP            EUR     SP00          A   \n",
      "2  EXR.M.GBP.EUR.SP00.A    M      GBP            EUR     SP00          A   \n",
      "3  EXR.M.GBP.EUR.SP00.A    M      GBP            EUR     SP00          A   \n",
      "4  EXR.M.GBP.EUR.SP00.A    M      GBP            EUR     SP00          A   \n",
      "\n",
      "  TIME_PERIOD  OBS_VALUE OBS_STATUS OBS_CONF  ...  COMPILATION  COVERAGE  \\\n",
      "0     1999-01   0.702913          A        F  ...          NaN       NaN   \n",
      "1     1999-02   0.688505          A        F  ...          NaN       NaN   \n",
      "2     1999-03   0.671270          A        F  ...          NaN       NaN   \n",
      "3     1999-04   0.665018          A        F  ...          NaN       NaN   \n",
      "4     1999-05   0.658252          A        F  ...          NaN       NaN   \n",
      "\n",
      "  DECIMALS  NAT_TITLE SOURCE_AGENCY  SOURCE_PUB                   TITLE  \\\n",
      "0        5        NaN           4F0         NaN  UK pound sterling/Euro   \n",
      "1        5        NaN           4F0         NaN  UK pound sterling/Euro   \n",
      "2        5        NaN           4F0         NaN  UK pound sterling/Euro   \n",
      "3        5        NaN           4F0         NaN  UK pound sterling/Euro   \n",
      "4        5        NaN           4F0         NaN  UK pound sterling/Euro   \n",
      "\n",
      "                                         TITLE_COMPL  UNIT  UNIT_MULT  \n",
      "0  ECB reference exchange rate, UK pound sterling...   GBP          0  \n",
      "1  ECB reference exchange rate, UK pound sterling...   GBP          0  \n",
      "2  ECB reference exchange rate, UK pound sterling...   GBP          0  \n",
      "3  ECB reference exchange rate, UK pound sterling...   GBP          0  \n",
      "4  ECB reference exchange rate, UK pound sterling...   GBP          0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# set the API endpoint URL to get data from api\n",
    "\n",
    "#Get  data from ECB SDMX 2.1 RESTful web service\n",
    "\n",
    "eurobank='https://sdw-wsrest.ecb.europa.eu/service/data/EXR/M.USD+GBP+JPY.EUR.SP00.A'\n",
    "\n",
    "\n",
    "headers = {'Accept':'text/csv'}\n",
    "params = {'startPeriod': '2023-02-09', 'endPeriod': '2023-02-10'}\n",
    "\n",
    "# send a GET request to the API endpoint\n",
    "response = requests.get(eurobank, headers=headers)\n",
    "response\n",
    "\n",
    "#check the response status code (200 means success)\n",
    "if response.status_code == 200:\n",
    "    data = response.content.decode('utf-8')\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "    print(df.head())\n",
    "    # Parse the CSV data\n",
    "    #reader = csv.DictReader(data.splitlines())\n",
    "    #rows = [row for row in reader]\n",
    "    # Process the data\n",
    "    #for row in rows:\n",
    "        #print(row)\n",
    "else:\n",
    "    print('Error retrieving data:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8273f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUCAS BARBOSA\\AppData\\Local\\Temp\\ipykernel_17752\\1601272642.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  products['CURRENCY']='USD'\n"
     ]
    }
   ],
   "source": [
    "df1=df[['CURRENCY','OBS_VALUE','TIME_PERIOD']].copy()\n",
    "df1.sort_values(['TIME_PERIOD'])\n",
    "products['CURRENCY']='USD'\n",
    "database=pd.merge(products,df1,how='outer',on='CURRENCY')\n",
    "database['price_euro']=round(database.price*database.OBS_VALUE,2)\n",
    "database=database[['category.name','price','price_euro','TIME_PERIOD']]\n",
    "database.rename(columns={'price':'price_usd', 'TIME_PERIOD':'time_period'},inplace=True)\n",
    "database['date']=datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "b6fecdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.to_csv('C:/Users\\/LUCAS BARBOSA/Desktop/my_project/jupyter/database.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47d9c3",
   "metadata": {},
   "source": [
    "Data Engineering in Production\n",
    "\n",
    "For these questions please provide a brief (1 paragraph) explanation. Diagrams can be included if it is helpful, but not required.\n",
    "\n",
    "Using typical sales data as an example, how would you ensure that a data pipeline is kept up to date with accurate data? What tools or process might you use so that sales data is updated daily?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0c82e",
   "metadata": {},
   "source": [
    "1)First of all apply some data quality process as duplicate entries, missing data. Checking for data consistency between different data sources. \n",
    "For instance, if you have sales data that is collected from multiple sources you  want to ensure that the data from each source is consistent and accurate.\n",
    "Regularly review and optimize the data pipeline to ensure that it is efficient and effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45343e32",
   "metadata": {},
   "source": [
    "2)Our sales and product data is constantly changing - returns can affect previous sales, pricing changes can affect product data tables, etc. - how would you go about building a data pipeline that is able to add new data while also changing or updating existing data that has changed at the source system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "2)#how would you go about building a data pipeline that is able to add new data while also changing or updating\n",
    "#existing data that has changed at the source system?\n",
    "existing_data = pd.read_csv('database.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Filter data that already exists in target system\n",
    "new_data = pd.DataFrame(data).merge(existing_data, on=['company', 'date'], how='left', indicator=True)\n",
    "new_data = new_data[new_data['_merge'] == 'left_only']\n",
    "\n",
    "# Append new data to existing data\n",
    "all_data = pd.concat([existing_data, new_data])\n",
    "\n",
    "# Write data to target system\n",
    "all_data.to_csv('database.csv', index=False)\n",
    "Implement data versioning: We can use a Python library like git to implement versioning:\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Add data to Git repository\n",
    "subprocess.run(['git', 'add', 'stocks.csv'])\n",
    "\n",
    "import logging\n",
    "import sentry_sdk\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='pipeline.log', level=logging.INFO)\n",
    "\n",
    "# Configure Sentry\n",
    "sentry_sdk.init(dsn='your-sentry-dsn')\n",
    "\n",
    "# Log errors and exceptions\n",
    "try:\n",
    "    # Run data pipeline code here\n",
    "except Exception as e:\n",
    "    logging.exception(e)\n",
    "    sentry_sdk.capture_exception(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
